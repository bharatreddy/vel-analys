{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import numpy\n",
    "import scipy.optimize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import bs4\n",
    "import urllib\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import ticker\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup some cutoff values we'll use in the analysis\n",
    "velCutoffUpper = 2000.\n",
    "velCutoffLower = 0.\n",
    "numPointsCutoffMLTMLAT = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dst_date</th>\n",
       "      <th>dst_index</th>\n",
       "      <th>dtStr</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>-11</td>\n",
       "      <td> 20110101</td>\n",
       "      <td> 01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>-11</td>\n",
       "      <td> 20110101</td>\n",
       "      <td> 02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td> -9</td>\n",
       "      <td> 20110101</td>\n",
       "      <td> 03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td> -5</td>\n",
       "      <td> 20110101</td>\n",
       "      <td> 04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 05:00:00</td>\n",
       "      <td> -3</td>\n",
       "      <td> 20110101</td>\n",
       "      <td> 05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dst_date  dst_index     dtStr hour\n",
       "0 2011-01-01 01:00:00        -11  20110101   01\n",
       "1 2011-01-01 02:00:00        -11  20110101   02\n",
       "2 2011-01-01 03:00:00         -9  20110101   03\n",
       "3 2011-01-01 04:00:00         -5  20110101   04\n",
       "4 2011-01-01 05:00:00         -3  20110101   05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dst index vals from wdc kyoto website\n",
    "# create a list of dates with monthly freq\n",
    "date_dst_arr = []\n",
    "dst_val = []\n",
    "dst_time_del = datetime.timedelta(hours = 1)\n",
    "start_date = datetime.datetime(2011,1,1)\n",
    "end_date = datetime.datetime(2014,12,31)\n",
    "daterange = pandas.date_range(start_date, end_date, freq=\"M\")\n",
    "for dt in daterange:\n",
    "    if dt.month <= 9:\n",
    "            monthStr = \"0\" + str(dt.month)\n",
    "    else:\n",
    "        monthStr = str(dt.month)\n",
    "    if dt.year >= 2015:\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_realtime\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    elif ( (dt.year > 2011) and (dt.year < 2015) ):\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_provisional\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    else:\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_final\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    conn = urllib.urlopen(currUrl)\n",
    "    htmlSource = conn.read()\n",
    "    soup = bs4.BeautifulSoup(htmlSource, 'html.parser')\n",
    "    dataResObj = soup.find(\"pre\", { \"class\" : \"data\" })\n",
    "    # get the data as a list of strings after removing white space\n",
    "    lines = dataResObj.text.strip().splitlines()\n",
    "    for line in lines[6:]:\n",
    "        columns = line.split()\n",
    "        if len( columns ) > 0. :\n",
    "            date_dst_arr.append( datetime.datetime( \\\n",
    "                dt.year, dt.month, int(columns[0]), 1 ) )\n",
    "            for cols in range( len( columns[1:] ) ) :\n",
    "                try:\n",
    "                    inNumberFloatTest = float(columns[cols + 1])\n",
    "                except:\n",
    "                    # split these cols as well and work on them!\n",
    "                    try:\n",
    "                        missedCols = columns[cols + 1].split(\"-\")[1:]\n",
    "                        if len(missedCols) >= 1:\n",
    "                            for mcols in missedCols:\n",
    "                                dst_val.append( -1*float( mcols ) )\n",
    "                                # now since we added the date earlier we need to be\n",
    "                                # careful about appending date values\n",
    "                                if ( len(date_dst_arr) != len(dst_val) ):\n",
    "                                    date_dst_arr.append ( date_dst_arr[-1] + dst_time_del )\n",
    "                    except:\n",
    "                        print \"something wrong with messed up vals!-->\", columns[cols + 1]\n",
    "                        continue\n",
    "                    continue\n",
    "                # I have to do this because of the messed up way Kyoto puts up the latest dst value..\n",
    "                # mixed with 9999 (fillers) like if latest dst is 1 then Kyoto puts it as 199999.....\n",
    "                if len( columns[ cols + 1 ] ) < 5 :\n",
    "                    dst_val.append( float( columns[ cols + 1 ] ) )\n",
    "                elif ( len( columns[ cols + 1 ] ) > 5 and columns[ cols + 1 ][0:3] != '999' ) :\n",
    "                    mixed_messed_dst = ''\n",
    "                    for jj in range(5) :\n",
    "                        if columns[ cols + 1 ][jj] != '9' :\n",
    "                            mixed_messed_dst = mixed_messed_dst + columns[ cols + 1 ][jj]\n",
    "\n",
    "                    if mixed_messed_dst != '-' :\n",
    "                        dst_val.append( float( mixed_messed_dst ) )\n",
    "                    else :\n",
    "                        dst_val.append( float( 'nan' ) )\n",
    "                else :\n",
    "                    dst_val.append( float( 'nan' ) )\n",
    "                if cols > 0 :\n",
    "                    date_dst_arr.append ( date_dst_arr[-1] + dst_time_del )\n",
    "# convert dst data to a dataframe\n",
    "dstDF = pandas.DataFrame(\n",
    "    {'dst_date': date_dst_arr,\n",
    "     'dst_index': dst_val\n",
    "    })\n",
    "# Remove dst values that are greater than 10,\n",
    "# They pull in data which is not looking good \n",
    "# when we check the plots\n",
    "dstDF = dstDF[ dstDF[\"dst_index\"] <= 10. ].reset_index(drop=True)\n",
    "dstDF[\"dtStr\"] = dstDF[\"dst_date\"].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "dstDF[\"hour\"] = dstDF[\"dst_date\"].apply(lambda x: x.strftime('%H'))\n",
    "dstDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently working with--> ../data/ae_2011.txt\n",
      "currently working with--> ../data/ae_2012.txt\n",
      "currently working with--> ../data/ae_2013.txt\n",
      "currently working with--> ../data/ae_2014.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtStr</th>\n",
       "      <th>date</th>\n",
       "      <th>datetimeStr</th>\n",
       "      <th>aur_type</th>\n",
       "      <th>minute</th>\n",
       "      <th>hour</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 20110101</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td> 20110101-00-00</td>\n",
       "      <td> AU</td>\n",
       "      <td> 00</td>\n",
       "      <td> 00</td>\n",
       "      <td> 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 20110101</td>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td> 20110101-01-00</td>\n",
       "      <td> AU</td>\n",
       "      <td> 00</td>\n",
       "      <td> 01</td>\n",
       "      <td> 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 20110101</td>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td> 20110101-02-00</td>\n",
       "      <td> AU</td>\n",
       "      <td> 00</td>\n",
       "      <td> 02</td>\n",
       "      <td> 18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 20110101</td>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td> 20110101-03-00</td>\n",
       "      <td> AU</td>\n",
       "      <td> 00</td>\n",
       "      <td> 03</td>\n",
       "      <td> 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 20110101</td>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td> 20110101-04-00</td>\n",
       "      <td> AU</td>\n",
       "      <td> 00</td>\n",
       "      <td> 04</td>\n",
       "      <td> 19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dtStr                date     datetimeStr aur_type minute hour  Value\n",
       "0  20110101 2011-01-01 00:00:00  20110101-00-00       AU     00   00     23\n",
       "1  20110101 2011-01-01 01:00:00  20110101-01-00       AU     00   01     25\n",
       "2  20110101 2011-01-01 02:00:00  20110101-02-00       AU     00   02     18\n",
       "3  20110101 2011-01-01 03:00:00  20110101-03-00       AU     00   03     23\n",
       "4  20110101 2011-01-01 04:00:00  20110101-04-00       AU     00   04     19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseDir = \"../data/\"\n",
    "# Setup some col names\n",
    "colList = []\n",
    "for colNum in range(64):\n",
    "    if colNum == 0: \n",
    "        colList.append( \"data1\" )\n",
    "    elif colNum == 1: \n",
    "        colList.append( \"aurDateStr\" )\n",
    "    elif colNum == 2: \n",
    "        colList.append( \"data2\" )\n",
    "    elif colNum == 63:\n",
    "        colList.append( \"hourly_average\" )\n",
    "    else:\n",
    "        currMinute = str(colNum-3)\n",
    "        if colNum-3 < 10:\n",
    "            currMinute = \"0\" + str(colNum-3)\n",
    "        colList.append( currMinute )\n",
    "        \n",
    "def split_aurtype_datetime(row):\n",
    "        if \"AU\" in row[\"aurDateStr\"]:\n",
    "            currDateHourStr = \"20\" + row[\"aurDateStr\"].split(\"U\")[0] +\\\n",
    "                \"-\" +  row[\"aurDateStr\"].split(\"U\")[1][:2]\n",
    "        elif \"AL\" in row[\"aurDateStr\"]:\n",
    "            currDateHourStr = \"20\" + row[\"aurDateStr\"].split(\"L\")[0] +\\\n",
    "                \"-\" +  row[\"aurDateStr\"].split(\"L\")[1][:2]\n",
    "        elif \"AO\" in row[\"aurDateStr\"]:\n",
    "            currDateHourStr = \"20\" + row[\"aurDateStr\"].split(\"O\")[0] +\\\n",
    "                \"-\" +  row[\"aurDateStr\"].split(\"O\")[1][:2]\n",
    "        else:\n",
    "            currDateHourStr = \"20\" + row[\"aurDateStr\"].split(\"E\")[0] +\\\n",
    "                \"-\" +  row[\"aurDateStr\"].split(\"E\")[1][:2]\n",
    "        return currDateHourStr   \n",
    "    \n",
    "def get_aur_type(row):\n",
    "        if \"AU\" in row[\"aurDateStr\"]:\n",
    "            return \"AU\"\n",
    "        elif \"AL\" in row[\"aurDateStr\"]:\n",
    "            return \"AL\"\n",
    "        elif \"AO\" in row[\"aurDateStr\"]:\n",
    "            return \"AO\"\n",
    "        else:\n",
    "            return \"AE\"\n",
    "\n",
    "rawAurDFList = []        \n",
    "# Loop through the directory and get all files\n",
    "for root, dirs, files in os.walk(baseDir):\n",
    "    for fName in files:\n",
    "        if \"ae\" not in fName:\n",
    "            continue\n",
    "        print \"currently working with-->\", root + fName\n",
    "        currAurDF = pandas.read_csv( root + fName, delim_whitespace=True,\\\n",
    "                                    header=None, names=colList )\n",
    "        currAurDF[\"dateStr\"] = currAurDF.apply( split_aurtype_datetime, axis=1 )\n",
    "        currAurDF[\"aur_type\"] = currAurDF.apply( get_aur_type, axis=1 )\n",
    "        rawAurDFList.append( currAurDF )\n",
    "rawAurDF = pandas.concat( rawAurDFList )\n",
    "# Convert the dataframe to\n",
    "selColList = [\"dateStr\", \"aur_type\"] + [ \"0\" + str(x) if x < 10 else str(x) for x in range(60) ]\n",
    "rawAurDF = rawAurDF[selColList]\n",
    "aurDF = pandas.melt(rawAurDF, id_vars=[\"dateStr\", \"aur_type\"], \n",
    "                  var_name=\"minute\", value_name=\"Value\")\n",
    "aurDF[\"datetimeStr\"] = aurDF[\"dateStr\"] + \"-\" + aurDF[\"minute\"]\n",
    "aurDF[\"date\"] = pandas.to_datetime(aurDF[\"datetimeStr\"], format='%Y%m%d-%H-%M')\n",
    "aurDF[\"hour\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%H'))\n",
    "aurDF[\"minute\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%M'))\n",
    "aurDF[\"dtStr\"] = aurDF[\"date\"].apply(lambda x: x.strftime('%Y%m%d'))\n",
    "aurDF = aurDF[ [ \"dtStr\", \"date\", \"datetimeStr\",\\\n",
    "                \"aur_type\", \"minute\", \"hour\", \"Value\" ] ]\n",
    "aurDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "# a helper function to convert seperate date\n",
    "# and time strings to datetime objects\n",
    "def convert_to_datetime(row):\n",
    "        # Given a datestr and a time string convert to a python datetime obj.\n",
    "        import datetime\n",
    "        datecolName=\"dtStr\"\n",
    "        timeColName=\"tmStr\"\n",
    "        currDateStr = str( int( row[datecolName] ) )\n",
    "    #     return currDateStr\n",
    "        if row[timeColName] < 10:\n",
    "            currTimeStr = \"000\" + str( int( row[timeColName] ) )\n",
    "        elif row[timeColName] < 100:\n",
    "            currTimeStr = \"00\" + str( int( row[timeColName] ) )\n",
    "        elif row[timeColName] < 1000:\n",
    "            currTimeStr = \"0\" + str( int( row[timeColName] ) )\n",
    "        else:\n",
    "            currTimeStr = str( int( row[timeColName] ) )\n",
    "        return datetime.datetime.strptime( currDateStr\\\n",
    "                        + \":\" + currTimeStr, \"%Y%m%d:%H%M\" )\n",
    "    \n",
    "fitVelFile = \"../data/all_fitted_vels.txt\"\n",
    "inpColNames = [\"normMLT\", \"MLAT\", \"vSaps\", \"azim\",\\\n",
    "                     \"vMagnErr\", \"azimErr\", \"dtStr\", \"tmStr\"]\n",
    "velsDataDF = pandas.read_csv(fitVelFile, sep=' ',\\\n",
    "                             header=None, names=inpColNames)\n",
    "velsDataDF[\"date\"] = velsDataDF.apply( convert_to_datetime, axis=1 )\n",
    "velsDataDF[\"dtStr\"] = velsDataDF[\"dtStr\"].astype(\"str\")\n",
    "# Discard unwanted values\n",
    "# We'll only consider those velocities \n",
    "# which lie between 0 and 2500 m/s\n",
    "# and located below 70 MLAT\n",
    "velsDataDF = velsDataDF[ (velsDataDF[\"vSaps\"] > velCutoffLower) \\\n",
    "                        & (velsDataDF[\"vSaps\"] < velCutoffUpper)\\\n",
    "                       ].reset_index(drop=True)\n",
    "velsDataDF = velsDataDF[ velsDataDF[\"MLAT\"] < 70. ].reset_index(drop=True)\n",
    "velsDataDF[\"hour\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%H'))\n",
    "velsDataDF[\"minute\"] = velsDataDF[\"date\"].apply(lambda x: x.strftime('%M'))\n",
    "# Now merge the dst and velocity DFs\n",
    "velsDataDF = pandas.merge( velsDataDF, dstDF,\\\n",
    "                          on=[\"dtStr\", \"hour\"], how='inner' )\n",
    "# We generally work with Dst bins, set them up\n",
    "# add dst_bins\n",
    "dstBins = [ -150, -75, -50, -25, -10, 10 ]\n",
    "velsDataDF = pandas.concat( [ velsDataDF, \\\n",
    "                    pandas.cut( velsDataDF[\"dst_index\"], \\\n",
    "                               bins=dstBins ) ], axis=1 )\n",
    "# Also merge with aurDF\n",
    "velsDataDF = pandas.merge( velsDataDF, aurDF,\\\n",
    "                         on=[\"dtStr\", \"minute\"], how='inner')\n",
    "# velsDataDF.columns = [  \"normMLT\", \"MLAT\", \"vSaps\", \"azim\",\\\n",
    "#                      \"vMagnErr\", \"azimErr\", \"dtStr\", \"tmStr\",\\\n",
    "#                       \"date\", \"hour\", \"dst_date\", \"dst_index\", \"dst_bin\" ]\n",
    "velsDataDF.head()\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####\n",
    "#### In this block we load Velocity data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter out some values where number of datapoints are pretty low.\n",
    "countDF = velsDataDF.groupby([ \"normMLT\", \"MLAT\" ]).size().reset_index()\n",
    "countDF.columns = [ \"normMLT\", \"MLAT\", \"count\" ]\n",
    "# Choose only columns which have atleast 100 points\n",
    "countDF = countDF[ countDF[\"count\"] >= numPointsCutoffMLTMLAT ].reset_index(drop=True)\n",
    "# Merge with velsDataDF to filter out unwanted values\n",
    "velsDataDF = pandas.merge( velsDataDF, countDF,\\\n",
    "                          on=[\"normMLT\", \"MLAT\"], how='inner' )\n",
    "velsDataDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll now divide data into MLT/MLAT bins and get some stats\n",
    "mltMlatMeanDF = velsDataDF.groupby( [ \"normMLT\", \"MLAT\" ] ).mean().reset_index()\n",
    "# Seaborn styling\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "seaMap = ListedColormap(sns.color_palette(\"Reds\"))\n",
    "# Plot using matplotlib\n",
    "fig1 = plt.figure()\n",
    "ax = fig1.add_subplot(111)\n",
    "mltMlatMeanDF.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=mltMlatMeanDF[\"vSaps\"]/10, cmap=seaMap, ax=ax)\n",
    "ax.set_ylabel(\"MLAT\")\n",
    "ax.set_xlabel(\"MLT\", fontsize=12)\n",
    "ax.set_title( \"Velocity Variations\" )\n",
    "plt.savefig(\"../figs/meanVelMLATMLT.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll now divide data into MLT/MLAT bins and get some stats\n",
    "mltMlatMeanDF = velsDataDF.groupby( [ \"normMLT\", \"MLAT\" ] ).mean().reset_index()\n",
    "# Seaborn styling\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "seaMap = ListedColormap(sns.color_palette(\"Reds\"))\n",
    "# Plot using matplotlib\n",
    "fig1 = plt.figure()\n",
    "ax = fig1.add_subplot(111)\n",
    "mltMlatMeanDF.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='azim',\n",
    "              s=20, cmap=seaMap, ax=ax)\n",
    "ax.set_ylabel(\"MLAT\")\n",
    "ax.set_xlabel(\"MLT\", fontsize=12)\n",
    "ax.set_title( \"Velocity Variations\" )\n",
    "plt.savefig(\"../figs/meanAzimMLATMLT.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 8))\n",
    "ax = f.add_subplot(1,1,1)\n",
    "\n",
    "# Not only velocity magnitudes we'd also \n",
    "# like to plot azimuths!\n",
    "# get the end points of vectors\n",
    "mltMlatMeanDF[\"plot_MLATEnd\"] = numpy.round( (mltMlatMeanDF[\"vSaps\"]/1000.) *\\\n",
    "                                numpy.cos( numpy.deg2rad(-90-1*mltMlatMeanDF[\"azim\"]) ) +\\\n",
    "                                mltMlatMeanDF[\"MLAT\"], 2)\n",
    "mltMlatMeanDF[\"plot_normMLTEnd\"] = numpy.round( (mltMlatMeanDF[\"vSaps\"]/1000.) *\\\n",
    "                                numpy.sin( numpy.deg2rad(-90-1*mltMlatMeanDF[\"azim\"]) ) +\\\n",
    "                                mltMlatMeanDF[\"normMLT\"], 2)\n",
    "\n",
    "# Now setup a velocity scale\n",
    "velScaleMin = 0.\n",
    "# round off max velocity to the next hundred\n",
    "velScaleMax = (mltMlatMeanDF[\"vSaps\"].max() + 100.)*100/100\\\n",
    "    - (mltMlatMeanDF[\"vSaps\"].max() + 100.)%100\n",
    "\n",
    "# Seaborn styling\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "seaMap = ListedColormap(sns.color_palette(\"Reds\"))\n",
    "\n",
    "mltMlatMeanDF.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=1., cmap=seaMap, vmin=velScaleMin, vmax=velScaleMax, ax=ax)\n",
    "ax1.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax1.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax1.set_title( \"SAPS Velcoties\", fontsize=14 )\n",
    "\n",
    "\n",
    "\n",
    "plotMLTends = mltMlatMeanDF['plot_normMLTEnd'].tolist()\n",
    "plotMLATends = mltMlatMeanDF['plot_MLATEnd'].tolist()\n",
    "plotMLTbegins = mltMlatMeanDF['normMLT'].tolist()\n",
    "plotMLATbegins = mltMlatMeanDF['MLAT'].tolist()\n",
    "plotVelMagns = mltMlatMeanDF['vSaps'].tolist()\n",
    "# Normalize velocities according to colorbar\n",
    "colNorm = Normalize( vmin=velScaleMin, vmax=velScaleMax )\n",
    "for currMLTend, currMLATend, currMLTbgn, currMLATbgn, currVel in\\\n",
    "        zip( plotMLTends, plotMLATends, plotMLTbegins, plotMLATbegins, plotVelMagns ) :\n",
    "        # get a appropriate color for each bar\n",
    "        currCol = seaMap( colNorm(currVel) )\n",
    "        ax.plot( [currMLTbgn, currMLTend], [ currMLATbgn, currMLATend ], color=currCol )        \n",
    "        ax.arrow( currMLTbgn, currMLATbgn, currMLTend-currMLTbgn, currMLATend-currMLATbgn,\\\n",
    "                 head_width=0.15, head_length=0.2, fc=currCol, ec=currCol)\n",
    "        \n",
    "plt.savefig(\"../figs/mltMlatVelVecs.pdf\",bbox_inches='tight')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Groupby Dst bin\n",
    "dstLocDF = velsDataDF.groupby( [ \"dst_bin\", \"normMLT\", \"MLAT\" ] ).mean().reset_index()\n",
    "dstLocDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a comparison plot of the data\n",
    "# for prob of occ at diff locs\n",
    "# Set up the matplotlib figure\n",
    "f = plt.figure(figsize=(12, 8))\n",
    "ax1 = f.add_subplot(3,2,1)\n",
    "ax2 = f.add_subplot(3,2,2)\n",
    "ax3 = f.add_subplot(3,2,3)\n",
    "ax4 = f.add_subplot(3,2,4)\n",
    "ax5 = f.add_subplot(3,2,5)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "seaMap = ListedColormap(sns.color_palette(\"Reds\"))\n",
    "# (-150,-75]\n",
    "dstSapsMLTLat15075 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-150, -75]\" ]\n",
    "dstSapsMLTLat15075.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=dstSapsMLTLat15075[\"vSaps\"]/10, cmap=seaMap, vmin=0, vmax=2000, ax=ax1, sharex=True)\n",
    "ax1.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax1.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax1.set_title( \"Dst between -150 & -75\", fontsize=14 )\n",
    "# (-75, -50]\n",
    "dstSapsMLTLat7550 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-75, -50]\" ]\n",
    "dstSapsMLTLat7550.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=dstSapsMLTLat7550[\"vSaps\"]/10, cmap=seaMap, vmin=0, vmax=2000, ax=ax2)\n",
    "ax2.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax2.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax2.set_title( \"Dst between -75 & -50\", fontsize=14 )\n",
    "# (-50, -25]\n",
    "dstSapsMLTLat5025 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-50, -25]\" ]\n",
    "dstSapsMLTLat5025.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=dstSapsMLTLat5025[\"vSaps\"]/10, cmap=seaMap, vmin=0, vmax=2000, ax=ax3)\n",
    "ax3.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax3.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax3.set_title( \"Dst between -50 & -25\", fontsize=14 )\n",
    "# (-25, -10]\n",
    "dstSapsMLTLat2510 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-25, -10]\" ]\n",
    "dstSapsMLTLat2510.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=dstSapsMLTLat2510[\"vSaps\"]/10, cmap=seaMap, vmin=0, vmax=2000, ax=ax4)\n",
    "ax4.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax4.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax4.set_title( \"Dst between -25 & -10\", fontsize=14 )\n",
    "# (-10, 10]\n",
    "dstSapsMLTLat1010 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-10, 10]\" ]\n",
    "dstSapsMLTLat1010.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=dstSapsMLTLat1010[\"vSaps\"]/10, cmap=seaMap, vmin=0, vmax=2000, ax=ax5)\n",
    "ax5.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax5.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax5.set_title( \"Dst between -10 & 10\", fontsize=14 )\n",
    "plt.savefig(\"../figs/allDstBinsVels.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a comparison plot of the data\n",
    "# for prob of occ at diff locs\n",
    "# Set up the matplotlib figure\n",
    "f = plt.figure(figsize=(12, 8))\n",
    "ax1 = f.add_subplot(3,2,1)\n",
    "ax2 = f.add_subplot(3,2,2)\n",
    "ax3 = f.add_subplot(3,2,3)\n",
    "ax4 = f.add_subplot(3,2,4)\n",
    "ax5 = f.add_subplot(3,2,5)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "seaMap = ListedColormap(sns.color_palette(\"RdBu\"))\n",
    "# (-150,-75]\n",
    "dstSapsMLTLat15075 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-150, -75]\" ]\n",
    "dstSapsMLTLat15075.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='azim',\n",
    "              s=25, cmap=seaMap, vmin=20, vmax=-20, ax=ax1, sharex=True)\n",
    "ax1.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax1.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax1.set_title( \"Dst between -150 & -75\", fontsize=14 )\n",
    "# (-75, -50]\n",
    "dstSapsMLTLat7550 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-75, -50]\" ]\n",
    "dstSapsMLTLat7550.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='azim',\n",
    "              s=25, cmap=seaMap, vmin=20, vmax=-20, ax=ax2)\n",
    "ax2.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax2.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax2.set_title( \"Dst between -75 & -50\", fontsize=14 )\n",
    "# (-50, -25]\n",
    "dstSapsMLTLat5025 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-50, -25]\" ]\n",
    "dstSapsMLTLat5025.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='azim',\n",
    "              s=25, cmap=seaMap, vmin=20, vmax=-20, ax=ax3)\n",
    "ax3.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax3.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax3.set_title( \"Dst between -50 & -25\", fontsize=14 )\n",
    "# (-25, -10]\n",
    "dstSapsMLTLat2510 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-25, -10]\" ]\n",
    "dstSapsMLTLat2510.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='azim',\n",
    "              s=25, cmap=seaMap, vmin=20, vmax=-20, ax=ax4)\n",
    "ax4.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax4.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax4.set_title( \"Dst between -25 & -10\", fontsize=14 )\n",
    "# (-10, 10]\n",
    "dstSapsMLTLat1010 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-10, 10]\" ]\n",
    "dstSapsMLTLat1010.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='azim',\n",
    "              s=25, cmap=seaMap, vmin=20, vmax=-20, ax=ax5)\n",
    "ax5.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax5.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax5.set_title( \"Dst between -10 & 10\", fontsize=14 )\n",
    "plt.savefig(\"../figs/allDstBinsVels.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not only velocity magnitudes we'd also \n",
    "# like to plot azimuths!\n",
    "# get the end points of vectors\n",
    "dstLocDF[\"plot_MLATEnd\"] = numpy.round( (dstLocDF[\"vSaps\"]/1000.) *\\\n",
    "                                numpy.cos( numpy.deg2rad(-90-1*dstLocDF[\"azim\"]) ) +\\\n",
    "                                dstLocDF[\"MLAT\"], 2)\n",
    "dstLocDF[\"plot_normMLTEnd\"] = numpy.round( (dstLocDF[\"vSaps\"]/1000.) *\\\n",
    "                                numpy.sin( numpy.deg2rad(-90-1*dstLocDF[\"azim\"]) ) +\\\n",
    "                                dstLocDF[\"normMLT\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 8))\n",
    "ax1 = f.add_subplot(3,2,1)\n",
    "ax2 = f.add_subplot(3,2,2)\n",
    "ax3 = f.add_subplot(3,2,3)\n",
    "ax4 = f.add_subplot(3,2,4)\n",
    "ax5 = f.add_subplot(3,2,5)\n",
    "\n",
    "# Now setup a velocity scale\n",
    "velScaleMin = 0.\n",
    "# round off max velocity to the next hundred\n",
    "velScaleMax = (dstLocDF[\"vSaps\"].max() + 100.)*100/100\\\n",
    "    - (dstLocDF[\"vSaps\"].max() + 100.)%100\n",
    "\n",
    "# Seaborn styling\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "seaMap = ListedColormap(sns.color_palette(\"Reds\"))\n",
    "\n",
    "fitResultsDF15075 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-150, -75]\" ]     \n",
    "fitResultsDF15075.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=1., cmap=seaMap, vmin=velScaleMin, vmax=velScaleMax, ax=ax1, sharex=True)\n",
    "ax1.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax1.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax1.set_title( \"Dst between -150 & -75\", fontsize=14 )\n",
    "\n",
    "plotMLTends = fitResultsDF15075['plot_normMLTEnd'].tolist()\n",
    "plotMLATends = fitResultsDF15075['plot_MLATEnd'].tolist()\n",
    "plotMLTbegins = fitResultsDF15075['normMLT'].tolist()\n",
    "plotMLATbegins = fitResultsDF15075['MLAT'].tolist()\n",
    "plotVelMagns = fitResultsDF15075['vSaps'].tolist()\n",
    "# Normalize velocities according to colorbar\n",
    "colNorm = Normalize( vmin=velScaleMin, vmax=velScaleMax )\n",
    "for currMLTend, currMLATend, currMLTbgn, currMLATbgn, currVel in\\\n",
    "        zip( plotMLTends, plotMLATends, plotMLTbegins, plotMLATbegins, plotVelMagns ) :\n",
    "        # get a appropriate color for each bar\n",
    "        currCol = seaMap( colNorm(currVel) )\n",
    "        ax1.plot( [currMLTbgn, currMLTend], [ currMLATbgn, currMLATend ], color=currCol )        \n",
    "        ax1.arrow( currMLTbgn, currMLATbgn, currMLTend-currMLTbgn, currMLATend-currMLATbgn,\\\n",
    "                 head_width=0.15, head_length=0.2, fc=currCol, ec=currCol)\n",
    "        \n",
    "        \n",
    "\n",
    "fitResultsDF7550 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-75, -50]\" ]     \n",
    "fitResultsDF7550.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=1., cmap=seaMap, vmin=velScaleMin, vmax=velScaleMax, ax=ax2)\n",
    "\n",
    "plotMLTends = fitResultsDF7550['plot_normMLTEnd'].tolist()\n",
    "plotMLATends = fitResultsDF7550['plot_MLATEnd'].tolist()\n",
    "plotMLTbegins = fitResultsDF7550['normMLT'].tolist()\n",
    "plotMLATbegins = fitResultsDF7550['MLAT'].tolist()\n",
    "plotVelMagns = fitResultsDF7550['vSaps'].tolist()\n",
    "# Normalize velocities according to colorbar\n",
    "colNorm = Normalize( vmin=velScaleMin, vmax=velScaleMax )\n",
    "for currMLTend, currMLATend, currMLTbgn, currMLATbgn, currVel in\\\n",
    "        zip( plotMLTends, plotMLATends, plotMLTbegins, plotMLATbegins, plotVelMagns ) :\n",
    "        # get a appropriate color for each bar\n",
    "        currCol = seaMap( colNorm(currVel) )\n",
    "        ax2.plot( [currMLTbgn, currMLTend], [ currMLATbgn, currMLATend ], color=currCol )        \n",
    "        ax2.arrow( currMLTbgn, currMLATbgn, currMLTend-currMLTbgn, currMLATend-currMLATbgn,\\\n",
    "                 head_width=0.15, head_length=0.2, fc=currCol, ec=currCol)\n",
    "        \n",
    "ax2.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax2.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax2.set_title( \"Dst between -75 & -50\", fontsize=14 )\n",
    "\n",
    "\n",
    "fitResultsDF5025 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-50, -25]\" ]     \n",
    "fitResultsDF5025.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=1., cmap=seaMap, vmin=velScaleMin, vmax=velScaleMax, ax=ax3)\n",
    "\n",
    "plotMLTends = fitResultsDF5025['plot_normMLTEnd'].tolist()\n",
    "plotMLATends = fitResultsDF5025['plot_MLATEnd'].tolist()\n",
    "plotMLTbegins = fitResultsDF5025['normMLT'].tolist()\n",
    "plotMLATbegins = fitResultsDF5025['MLAT'].tolist()\n",
    "plotVelMagns = fitResultsDF5025['vSaps'].tolist()\n",
    "# Normalize velocities according to colorbar\n",
    "colNorm = Normalize( vmin=velScaleMin, vmax=velScaleMax )\n",
    "for currMLTend, currMLATend, currMLTbgn, currMLATbgn, currVel in\\\n",
    "        zip( plotMLTends, plotMLATends, plotMLTbegins, plotMLATbegins, plotVelMagns ) :\n",
    "        # get a appropriate color for each bar\n",
    "        currCol = seaMap( colNorm(currVel) )\n",
    "        ax3.plot( [currMLTbgn, currMLTend], [ currMLATbgn, currMLATend ], color=currCol )        \n",
    "        ax3.arrow( currMLTbgn, currMLATbgn, currMLTend-currMLTbgn, currMLATend-currMLATbgn,\\\n",
    "                 head_width=0.15, head_length=0.2, fc=currCol, ec=currCol)\n",
    "        \n",
    "ax3.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax3.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax3.set_title( \"Dst between -50 & -25\", fontsize=14 )\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "fitResultsDF2510 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-25, -10]\" ]     \n",
    "fitResultsDF2510.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=1., cmap=seaMap, vmin=velScaleMin, vmax=velScaleMax, ax=ax4)\n",
    "\n",
    "plotMLTends = fitResultsDF2510['plot_normMLTEnd'].tolist()\n",
    "plotMLATends = fitResultsDF2510['plot_MLATEnd'].tolist()\n",
    "plotMLTbegins = fitResultsDF2510['normMLT'].tolist()\n",
    "plotMLATbegins = fitResultsDF2510['MLAT'].tolist()\n",
    "plotVelMagns = fitResultsDF2510['vSaps'].tolist()\n",
    "# Normalize velocities according to colorbar\n",
    "colNorm = Normalize( vmin=velScaleMin, vmax=velScaleMax )\n",
    "for currMLTend, currMLATend, currMLTbgn, currMLATbgn, currVel in\\\n",
    "        zip( plotMLTends, plotMLATends, plotMLTbegins, plotMLATbegins, plotVelMagns ) :\n",
    "        # get a appropriate color for each bar\n",
    "        currCol = seaMap( colNorm(currVel) )\n",
    "        ax4.plot( [currMLTbgn, currMLTend], [ currMLATbgn, currMLATend ], color=currCol )        \n",
    "        ax4.arrow( currMLTbgn, currMLATbgn, currMLTend-currMLTbgn, currMLATend-currMLATbgn,\\\n",
    "                 head_width=0.15, head_length=0.2, fc=currCol, ec=currCol)\n",
    "        \n",
    "\n",
    "ax4.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax4.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax4.set_title( \"Dst between -25 & -10\", fontsize=14 )        \n",
    "        \n",
    "        \n",
    "fitResultsDF1010 = dstLocDF[ dstLocDF[\"dst_bin\"] == \"(-10, 10]\" ]     \n",
    "fitResultsDF1010.plot( kind='scatter',\n",
    "              x='normMLT',\n",
    "              y='MLAT',\n",
    "              c='vSaps',\n",
    "              s=1., cmap=seaMap, vmin=velScaleMin, vmax=velScaleMax, ax=ax5)\n",
    "\n",
    "plotMLTends = fitResultsDF1010['plot_normMLTEnd'].tolist()\n",
    "plotMLATends = fitResultsDF1010['plot_MLATEnd'].tolist()\n",
    "plotMLTbegins = fitResultsDF1010['normMLT'].tolist()\n",
    "plotMLATbegins = fitResultsDF1010['MLAT'].tolist()\n",
    "plotVelMagns = fitResultsDF1010['vSaps'].tolist()\n",
    "# Normalize velocities according to colorbar\n",
    "colNorm = Normalize( vmin=velScaleMin, vmax=velScaleMax )\n",
    "for currMLTend, currMLATend, currMLTbgn, currMLATbgn, currVel in\\\n",
    "        zip( plotMLTends, plotMLATends, plotMLTbegins, plotMLATbegins, plotVelMagns ) :\n",
    "        # get a appropriate color for each bar\n",
    "        currCol = seaMap( colNorm(currVel) )\n",
    "        ax5.plot( [currMLTbgn, currMLTend], [ currMLATbgn, currMLATend ], color=currCol )        \n",
    "        ax5.arrow( currMLTbgn, currMLATbgn, currMLTend-currMLTbgn, currMLATend-currMLATbgn,\\\n",
    "                 head_width=0.15, head_length=0.2, fc=currCol, ec=currCol)\n",
    "ax5.set_xlabel(\"MLT\", fontsize=14)\n",
    "ax5.set_ylabel(\"Latitude\", fontsize=14)\n",
    "ax5.set_title( \"Dst between -10 & 10\", fontsize=14 )\n",
    "plt.savefig(\"../figs/allDstBinsVelVecs.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
