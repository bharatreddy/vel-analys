{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import numpy\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import ticker\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup some cutoff values we'll use in the analysis\n",
    "velCutoffUpper = 2000.\n",
    "velCutoffLower = 0.\n",
    "numPointsCutoffMLTMLAT = 250\n",
    "mlatCutOffUpper = 70.\n",
    "probOccCutoff = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:32: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normMLT</th>\n",
       "      <th>MLAT</th>\n",
       "      <th>vSaps</th>\n",
       "      <th>azim</th>\n",
       "      <th>dst_bin</th>\n",
       "      <th>dst_index</th>\n",
       "      <th>count</th>\n",
       "      <th>maxCntDst</th>\n",
       "      <th>vel_bin</th>\n",
       "      <th>dst_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>927.34</td>\n",
       "      <td>-12.52</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>293</td>\n",
       "      <td>508</td>\n",
       "      <td>(900, 1000]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>755.23</td>\n",
       "      <td>-17.91</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>277</td>\n",
       "      <td>508</td>\n",
       "      <td>(700, 800]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>743.78</td>\n",
       "      <td>-17.19</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>277</td>\n",
       "      <td>508</td>\n",
       "      <td>(700, 800]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>800.52</td>\n",
       "      <td>-14.51</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>277</td>\n",
       "      <td>508</td>\n",
       "      <td>(800, 900]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>535.88</td>\n",
       "      <td>-19.86</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>277</td>\n",
       "      <td>508</td>\n",
       "      <td>(500, 600]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   normMLT  MLAT   vSaps   azim    dst_bin  dst_index  count  maxCntDst  \\\n",
       "0      1.0  58.0  927.34 -12.52  (-10, 10]       -6.0    293        508   \n",
       "1     -3.0  61.0  755.23 -17.91  (-10, 10]       -8.0    277        508   \n",
       "2     -3.0  61.0  743.78 -17.19  (-10, 10]       -8.0    277        508   \n",
       "3     -3.0  61.0  800.52 -14.51  (-10, 10]       -8.0    277        508   \n",
       "4     -3.0  61.0  535.88 -19.86  (-10, 10]       -8.0    277        508   \n",
       "\n",
       "       vel_bin  dst_mean  \n",
       "0  (900, 1000]        -3  \n",
       "1   (700, 800]        -3  \n",
       "2   (700, 800]        -3  \n",
       "3   (800, 900]        -3  \n",
       "4   (500, 600]        -3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velGmagDF = pandas.read_csv(\"../data/processed-vels-geomag.txt\", sep=' ')\n",
    "velGmagDF = velGmagDF.drop('Unnamed: 0', axis=1)\n",
    "# Discard unwanted values\n",
    "# We'll only consider those velocities \n",
    "# which lie between 0 and 2500 m/s\n",
    "# and located below 70 MLAT\n",
    "velGmagDF = velGmagDF[ (velGmagDF[\"vSaps\"] > velCutoffLower) \\\n",
    "                        & (velGmagDF[\"vSaps\"] < velCutoffUpper)\\\n",
    "                       ].reset_index(drop=True)\n",
    "velGmagDF = velGmagDF[ velGmagDF[\"MLAT\"] < mlatCutOffUpper ].reset_index(drop=True)\n",
    "# Now filter out velocities which have very few rate of occ.\n",
    "# We calculat the prob and remove every measurement below 0.2 prob of occ.\n",
    "mlatMLTDstCountDF = velGmagDF.groupby( [\"MLAT\", \"normMLT\", \"dst_bin\"] )[\"vSaps\"].count().reset_index()\n",
    "mlatMLTDstCountDF.columns = [ \"MLAT\", \"normMLT\", \"dst_bin\", \"count\" ]\n",
    "dstMaxCntDF = mlatMLTDstCountDF.groupby( [\"dst_bin\"] )[\"count\"].max().reset_index()\n",
    "dstMaxCntDF.columns = [ \"dst_bin\", \"maxCntDst\" ]\n",
    "mlatMLTDstCountDF = pandas.merge( mlatMLTDstCountDF, dstMaxCntDF, on=[ \"dst_bin\" ] )\n",
    "mlatMLTDstCountDF[\"probOcc\"] = mlatMLTDstCountDF[\"count\"]/mlatMLTDstCountDF[\"maxCntDst\"]\n",
    "mlatMLTDstCountDF = mlatMLTDstCountDF[ mlatMLTDstCountDF[\"probOcc\"] > probOccCutoff ].reset_index(drop=True)\n",
    "# Filter out MLATs and MLTs (at the Dst bins)\n",
    "# where number of measurements is low. We do\n",
    "# this by merging the mlatMLTDstCountDF with velDF.\n",
    "velGmagDF = pandas.merge( velGmagDF,\\\n",
    "                         mlatMLTDstCountDF,\\\n",
    "                         on=[ \"MLAT\", \"normMLT\", \"dst_bin\" ] )\n",
    "velGmagDF = velGmagDF[ [ \"normMLT\", \"MLAT\", \"vSaps\",\\\n",
    "                        \"azim\", \"dst_bin\", \"dst_index\", \"count\", \"maxCntDst\" ] ]\n",
    "# Divide the velocities into bins\n",
    "velBins = [ v for v in range(0,int(velCutoffUpper)+100,100) ]\n",
    "velGmagDF = pandas.concat( [ velGmagDF, \\\n",
    "                    pandas.cut( velGmagDF[\"vSaps\"], \\\n",
    "                               bins=velBins ) ], axis=1 )\n",
    "velGmagDF.columns = [ \"normMLT\", \"MLAT\", \"vSaps\",\\\n",
    "                        \"azim\", \"dst_bin\", \"dst_index\", \"count\",\\\n",
    "                         \"maxCntDst\", \"vel_bin\" ]\n",
    "# velGmagDF.head()\n",
    "# Get a DF with mean Dst in each bin\n",
    "dstMeanDF = velGmagDF.groupby( [\"dst_bin\"] ).mean()[\"dst_index\"].astype(int).reset_index()\n",
    "dstMeanDF.columns = [ \"dst_bin\", \"dst_mean\" ]\n",
    "velGmagDF = pandas.merge( velGmagDF, dstMeanDF, on=[\"dst_bin\"] )\n",
    "velGmagDF = velGmagDF.sort( [\"dst_mean\"], ascending=False ).reset_index(drop=True)\n",
    "velGmagDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:39: RuntimeWarning: divide by zero encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:40: RuntimeWarning: invalid value encountered in multiply\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.py:875: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.py:875: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.py:1731: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  cond2 = (x >= self.b) & cond0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.00000000e+04  -1.00000000e+04   1.00000000e+03   1.00000000e+03\n",
      "  -1.00000000e+01  -1.00000000e+01   1.00000000e+02   1.00000000e+02\n",
      "   1.00000000e+01   1.00000000e+01   1.00000000e+00   1.00000000e+00\n",
      "   1.00000000e+01   1.00000000e+01  -1.00000000e+00  -1.00000000e+00\n",
      "   1.00000000e+02   1.00000000e+02  -1.00000000e+02  -1.00000000e+02\n",
      "   1.00000000e+02   1.00000000e+02   4.00000000e+00   4.00000000e+00\n",
      "   1.00000000e-01   1.00000000e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/optimize/minpack.py:715: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define the fitting function\n",
    "# We know that the velocities are \n",
    "# exhibiting a skew normal distribution\n",
    "def fit_vel_pdf((mlt,mlat, dst, inpVels), a_ascmlt, b_ascmlt, a_bscmlt, b_bscmlt, a_cscmlt, b_cscmlt,\\\n",
    "               a_asclat, b_asclat, a_bsclat, b_bsclat,\\\n",
    "               a_ashmlt, b_ashmlt, a_bshmlt, b_bshmlt,\\\n",
    "               a_ashlat, b_ashlat, a_bshlat, b_bshlat,\\\n",
    "               a_alcmlt, b_alcmlt, a_blcmlt, b_blcmlt,\\\n",
    "               a_alclat, b_alclat, a_blclat, b_blclat):\n",
    "    \n",
    "    # model scale parameters\n",
    "    # mlt\n",
    "    a_scale_mlt = a_ascmlt + b_ascmlt * dst\n",
    "    b_scale_mlt = a_bscmlt + b_bscmlt * dst\n",
    "    c_scale_mlt = a_cscmlt + b_cscmlt * dst\n",
    "    # mlat\n",
    "    a_scale_mlat = a_asclat + b_asclat * dst\n",
    "    b_scale_mlat = a_bsclat + b_bsclat * dst\n",
    "    # func\n",
    "    scale = ( a_scale_mlt + b_scale_mlt*(mlt) + c_scale_mlt*(mlt**2) ) * ( a_scale_mlat + b_scale_mlat*(mlat) )\n",
    "    \n",
    "    # model shape parameters\n",
    "    # mlt\n",
    "    a_shape_mlt = a_ashmlt + b_ashmlt * dst\n",
    "    b_shape_mlt = a_bshmlt + b_bshmlt * dst\n",
    "    # mlat\n",
    "    a_shape_mlat = a_ashlat + b_ashlat * dst\n",
    "    b_shape_mlat = a_bshlat + b_bshlat * dst\n",
    "    # func\n",
    "    shape = ( a_shape_mlt + b_shape_mlt*(mlt) ) * ( a_shape_mlat + b_shape_mlat*(mlat) )\n",
    "    \n",
    "    # model loc parameters\n",
    "    # mlt\n",
    "    a_loc_mlt = a_alcmlt + b_alcmlt * dst\n",
    "    b_loc_mlt = a_blcmlt + b_blcmlt * dst\n",
    "    # malt\n",
    "    a_loc_mlat = a_alclat + b_alclat * dst\n",
    "    b_loc_mlat = a_blclat + b_blclat * dst\n",
    "    # func\n",
    "    loc = ( a_loc_mlt + b_loc_mlt*(mlt) ) * ( a_loc_mlat*numpy.exp(b_loc_mlat*mlat) )\n",
    "    \n",
    "    # we need to adjust the skewnormal distribution\n",
    "    # to account fot loc and scale parameters\n",
    "    inpData = (inpVels - loc)/scale\n",
    "    skNrml = 2*stats.norm.pdf(inpData)*stats.norm.cdf(shape*inpData)\n",
    "     \n",
    "    return skNrml.ravel()\n",
    "\n",
    "initGuess = ( -1e+4, -1e+4, 1e3, 1e3, -10, -10,\\\n",
    "             100, 100, 10, 10,\\\n",
    "             1, 1, 10, 10,\\\n",
    "            -1, -1, 100, 100,\\\n",
    "            -100, -100, 100, 100,\\\n",
    "            4, 4, 0.1, 0.1)\n",
    "popt2, pcov2 = curve_fit(fit_vel_pdf, (velGmagDF['MLAT'].T,velGmagDF['normMLT'].T,velGmagDF['dst_index'].T,\\\n",
    "                                       velGmagDF['vSaps'].T), velGmagDF['vSaps'], p0=initGuess)\n",
    "print popt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15865525  0.84134475  0.97724987  0.97724987  0.97724987  0.9986501\n",
      "  0.99996833]\n"
     ]
    }
   ],
   "source": [
    "aa = [ -1,1,2,2,2,3,4 ]\n",
    "print stats.norm.cdf(aa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
