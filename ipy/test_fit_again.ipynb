{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import numpy\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import ticker\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup some cutoff values we'll use in the analysis\n",
    "velCutoffUpper = 2000.\n",
    "velCutoffLower = 0.\n",
    "numPointsCutoffMLTMLAT = 250\n",
    "mlatCutOffUpper = 70.\n",
    "probOccCutoff = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:32: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normMLT</th>\n",
       "      <th>MLAT</th>\n",
       "      <th>vSaps</th>\n",
       "      <th>azim</th>\n",
       "      <th>dst_index</th>\n",
       "      <th>vel_bin</th>\n",
       "      <th>dst_bin</th>\n",
       "      <th>dst_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>164.32</td>\n",
       "      <td>-19.01</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>(100, 200]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>171.45</td>\n",
       "      <td>-16.11</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(100, 200]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>174.58</td>\n",
       "      <td>-14.80</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>(100, 200]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>176.98</td>\n",
       "      <td>-6.09</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>(100, 200]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>59.5</td>\n",
       "      <td>178.11</td>\n",
       "      <td>-6.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(100, 200]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   normMLT  MLAT   vSaps   azim  dst_index     vel_bin    dst_bin  dst_mean\n",
       "0      1.0  58.5  164.32 -19.01       -7.0  (100, 200]  (-10, 10]        -3\n",
       "1      1.0  57.0  171.45 -16.11       -1.0  (100, 200]  (-10, 10]        -3\n",
       "2      1.0  59.0  174.58 -14.80       -7.0  (100, 200]  (-10, 10]        -3\n",
       "3      1.0  59.0  176.98  -6.09       -7.0  (100, 200]  (-10, 10]        -3\n",
       "4      2.0  59.5  178.11  -6.20        3.0  (100, 200]  (-10, 10]        -3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velGmagDF = pandas.read_csv(\"../data/processed-vels-geomag.txt\", sep=' ')\n",
    "velGmagDF = velGmagDF.drop('Unnamed: 0', axis=1)\n",
    "# Discard unwanted values\n",
    "# We'll only consider those velocities \n",
    "# which lie between 0 and 2500 m/s\n",
    "# and located below 70 MLAT\n",
    "velGmagDF = velGmagDF[ (velGmagDF[\"vSaps\"] > velCutoffLower) \\\n",
    "                        & (velGmagDF[\"vSaps\"] < velCutoffUpper)\\\n",
    "                       ].reset_index(drop=True)\n",
    "velGmagDF = velGmagDF[ velGmagDF[\"MLAT\"] < mlatCutOffUpper ].reset_index(drop=True)\n",
    "# Now filter out velocities which have very few rate of occ.\n",
    "# We calculat the prob and remove every measurement below 0.2 prob of occ.\n",
    "mlatMLTDstCountDF = velGmagDF.groupby( [\"MLAT\", \"normMLT\", \"dst_bin\"] )[\"vSaps\"].count().reset_index()\n",
    "mlatMLTDstCountDF.columns = [ \"MLAT\", \"normMLT\", \"dst_bin\", \"count\" ]\n",
    "dstMaxCntDF = mlatMLTDstCountDF.groupby( [\"dst_bin\"] )[\"count\"].max().reset_index()\n",
    "dstMaxCntDF.columns = [ \"dst_bin\", \"maxCntDst\" ]\n",
    "mlatMLTDstCountDF = pandas.merge( mlatMLTDstCountDF, dstMaxCntDF, on=[ \"dst_bin\" ] )\n",
    "mlatMLTDstCountDF[\"probOcc\"] = mlatMLTDstCountDF[\"count\"]/mlatMLTDstCountDF[\"maxCntDst\"]\n",
    "mlatMLTDstCountDF = mlatMLTDstCountDF[ mlatMLTDstCountDF[\"probOcc\"] > probOccCutoff ].reset_index(drop=True)\n",
    "# Filter out MLATs and MLTs (at the Dst bins)\n",
    "# where number of measurements is low. We do\n",
    "# this by merging the mlatMLTDstCountDF with velDF.\n",
    "velGmagDF = pandas.merge( velGmagDF,\\\n",
    "                         mlatMLTDstCountDF,\\\n",
    "                         on=[ \"MLAT\", \"normMLT\", \"dst_bin\" ] )\n",
    "velGmagDF = velGmagDF[ [ \"normMLT\", \"MLAT\", \"vSaps\",\\\n",
    "                        \"azim\", \"dst_bin\", \"dst_index\", \"count\", \"maxCntDst\" ] ]\n",
    "# Divide the velocities into bins\n",
    "velBins = [ v for v in range(0,int(velCutoffUpper)+100,100) ]\n",
    "velGmagDF = pandas.concat( [ velGmagDF, \\\n",
    "                    pandas.cut( velGmagDF[\"vSaps\"], \\\n",
    "                               bins=velBins ) ], axis=1 )\n",
    "velGmagDF.columns = [ \"normMLT\", \"MLAT\", \"vSaps\",\\\n",
    "                        \"azim\", \"dst_bin\", \"dst_index\", \"count\",\\\n",
    "                         \"maxCntDst\", \"vel_bin\" ]\n",
    "# velGmagDF.head()\n",
    "# Get a DF with mean Dst in each bin\n",
    "dstMeanDF = velGmagDF.groupby( [\"dst_bin\"] ).mean()[\"dst_index\"].astype(int).reset_index()\n",
    "dstMeanDF.columns = [ \"dst_bin\", \"dst_mean\" ]\n",
    "velGmagDF = pandas.merge( velGmagDF, dstMeanDF, on=[\"dst_bin\"] )\n",
    "velGmagDF = velGmagDF.sort( [\"dst_mean\", \"vSaps\"], ascending=[False,True] ).reset_index(drop=True)\n",
    "velCatOrderd = ['(0, 100]', '(100, 200]', '(200, 300]', '(300, 400]', '(400, 500]',\\\n",
    "          '(500, 600]', '(600, 700]', '(700, 800]',\\\n",
    "          '(800, 900]', '(900, 1000]', '(1000, 1100]', '(1100, 1200]',\\\n",
    "          '(1200, 1300]', '(1300, 1400]', '(1400, 1500]',\\\n",
    "          '(1500, 1600]', '(1600, 1700]', '(1700, 1800]',\\\n",
    "          '(1800, 1900]', '(1900, 2000]' ]\n",
    "\n",
    "velGmagDF['vel_bin'] = pandas.Categorical(\n",
    "    velGmagDF['vel_bin'], \n",
    "    categories=velCatOrderd, \n",
    "    ordered=True\n",
    ")\n",
    "# We need only a few cols\n",
    "velGmagDF = velGmagDF[ [ \"normMLT\", \"MLAT\", \"vSaps\", \"azim\", \"dst_index\",\\\n",
    "                        \"vel_bin\", \"dst_bin\", \"dst_mean\" ] ]\n",
    "velGmagDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:20: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "# calculate prob densities of vel bins at a given MLAT, MLT and Dst\n",
    "# We can them compare these with our estimates of skewnormal!!!\n",
    "probVelDstDF = velGmagDF.groupby( [ \"vel_bin\", \"dst_bin\", \"MLAT\", \"normMLT\" ] ).count()[\"vSaps\"].reset_index()\n",
    "probVelDstDF.columns = [ \"vel_bin\", \"dst_bin\", \"MLAT\", \"normMLT\", \"count\" ]\n",
    "# get the max count at dst, mlat and mlt\n",
    "maxCntVelDF = velGmagDF.groupby( [ \"dst_bin\", \"MLAT\", \"normMLT\" ] ).count()[\"vSaps\"].reset_index()\n",
    "maxCntVelDF.columns = [ \"dst_bin\", \"MLAT\", \"normMLT\", \"tot_count\" ]\n",
    "probVelDstDF = pandas.merge( probVelDstDF, maxCntVelDF, on=[ \"dst_bin\", \"MLAT\", \"normMLT\" ] )\n",
    "# Fill NaNs with zeros\n",
    "probVelDstDF[\"count\"].fillna(0.,inplace=True)\n",
    "# calculate probs\n",
    "probVelDstDF[\"prob\"] = probVelDstDF[\"count\"] / probVelDstDF[\"tot_count\"]\n",
    "probVelDstDF = probVelDstDF.round(2)\n",
    "velCatOrderd = ['(0, 100]', '(100, 200]', '(200, 300]', '(300, 400]', '(400, 500]',\\\n",
    "          '(500, 600]', '(600, 700]', '(700, 800]',\\\n",
    "          '(800, 900]', '(900, 1000]', '(1000, 1100]', '(1100, 1200]',\\\n",
    "          '(1200, 1300]', '(1300, 1400]', '(1400, 1500]',\\\n",
    "          '(1500, 1600]', '(1600, 1700]', '(1700, 1800]',\\\n",
    "          '(1800, 1900]', '(1900, 2000]' ]\n",
    "probVelDstDF['vel_bin'] = pandas.Categorical(\n",
    "    probVelDstDF['vel_bin'], \n",
    "    categories=velCatOrderd, \n",
    "    ordered=True\n",
    ")\n",
    "probVelDstDF = probVelDstDF.sort(\"vel_bin\").reset_index(drop=True)\n",
    "# Merge with velGmagDF to combine all cols we need to one DF\n",
    "velGmagDF = pandas.merge( probVelDstDF, velGmagDF,\\\n",
    "                            on=[ \"vel_bin\", \"dst_bin\", \"MLAT\", \"normMLT\" ] ).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vel_bin</th>\n",
       "      <th>dst_bin</th>\n",
       "      <th>MLAT</th>\n",
       "      <th>normMLT</th>\n",
       "      <th>count</th>\n",
       "      <th>tot_count</th>\n",
       "      <th>prob</th>\n",
       "      <th>dst_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 100]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>56.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 100]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 100]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>60.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 100]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>60.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 100]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vel_bin    dst_bin  MLAT  normMLT  count  tot_count  prob  dst_mean\n",
       "0  (0, 100]  (-10, 10]  56.5      1.0    0.0        106   0.0      -4.0\n",
       "1  (0, 100]  (-10, 10]  60.5      0.0    0.0        453   0.0      -4.0\n",
       "2  (0, 100]  (-10, 10]  60.5      1.0    0.0        426   0.0      -4.0\n",
       "3  (0, 100]  (-10, 10]  60.5     -1.0    0.0        385   0.0      -4.0\n",
       "4  (0, 100]  (-10, 10]  60.0      2.0    0.0        221   0.0      -4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dstMeanDF = velGmagDF.groupby( [\"dst_bin\"] ).mean()[\"dst_index\"].reset_index()\n",
    "dstMeanDF[\"dst_index\"] = [ round(x) for x in dstMeanDF[\"dst_index\"] ]\n",
    "dstMeanDF.columns = [ \"dst_bin\", \"dst_mean\" ]\n",
    "probVelDstDF = pandas.merge( probVelDstDF, dstMeanDF, on=[\"dst_bin\"] )\n",
    "allDstBins = probVelDstDF[\"dst_bin\"].unique()\n",
    "probVelDstDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:116: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1190e66c5119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# KDE and plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvelsArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2100.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskewnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubSetVelDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vSaps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mvelKernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0msubSetVelDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vSaps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"scott\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpdf_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskewnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvelsArr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, *args, **kwds)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                                          'scale' in kwds):\n\u001b[1;32m   2170\u001b[0m             \u001b[0;31m# get distribution specific starting locations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fitstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2172\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNarg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.pyc\u001b[0m in \u001b[0;36m_fitstart\u001b[0;34m(self, data, args)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2019\u001b[0;31m         \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_loc_scale_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.pyc\u001b[0m in \u001b[0;36m_fit_loc_scale_support\u001b[0;34m(self, data, *args)\u001b[0m\n\u001b[1;32m   2237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m         \u001b[0;31m# Use the moment-based estimates if they are compatible with the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2239\u001b[0;31m         \u001b[0mdata_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2240\u001b[0m         \u001b[0mdata_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma_hat\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdata_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata_b\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mb_hat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2395\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m         return _methods._amin(a, axis=axis,\n\u001b[0;32m-> 2397\u001b[0;31m                             out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "# Select a subset of the data!\n",
    "selDstBin = \"(-10, 10]\"\n",
    "subSetProbDF = probVelDstDF[ (probVelDstDF[\"dst_bin\"] == selDstBin) &\\\n",
    "                   (probVelDstDF[\"MLAT\"] == 59) &\\\n",
    "                   (probVelDstDF[\"normMLT\"] == -3)].reset_index(drop=True)\n",
    "\n",
    "subSetVelDF = velGmagDF[ (velGmagDF[\"dst_bin\"] == selDstBin) &\\\n",
    "                   (velGmagDF[\"MLAT\"] == 59) &\\\n",
    "                   (velGmagDF[\"normMLT\"] == -3)].reset_index(drop=True)\n",
    "# KDE and plotting\n",
    "velsArr = numpy.arange(0.,2100.,100.)\n",
    "shape, loc, scale = stats.skewnorm.fit(subSetVelDF[\"vSaps\"])\n",
    "velKernel = stats.gaussian_kde( subSetVelDF[\"vSaps\"], bw_method=\"scott\" )\n",
    "pdf_fitted = stats.skewnorm.pdf(velsArr, shape, loc, scale)\n",
    "# print pdf_fitted\n",
    "\n",
    "f = plt.figure(figsize=(12, 8))\n",
    "ax = f.add_subplot(1,1,1)\n",
    "# subSetProbDF.plot( x=\"vel_bin\", y=\"prob\", kind=\"bar\", ax=ax )\n",
    "ax.plot(velsArr, velKernel.pdf( velsArr ), 'b--', lw=5, alpha=0.6)\n",
    "ax.plot(velsArr, pdf_fitted, 'r-', lw=5, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531\n"
     ]
    }
   ],
   "source": [
    "print velKernel.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:39: RuntimeWarning: divide by zero encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:40: RuntimeWarning: invalid value encountered in multiply\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.py:875: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.py:875: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.py:1731: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  cond2 = (x >= self.b) & cond0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.00000000e+04  -1.00000000e+04   1.00000000e+03   1.00000000e+03\n",
      "  -1.00000000e+01  -1.00000000e+01   1.00000000e+02   1.00000000e+02\n",
      "   1.00000000e+01   1.00000000e+01   1.00000000e+00   1.00000000e+00\n",
      "   1.00000000e+01   1.00000000e+01  -1.00000000e+00  -1.00000000e+00\n",
      "   1.00000000e+02   1.00000000e+02  -1.00000000e+02  -1.00000000e+02\n",
      "   1.00000000e+02   1.00000000e+02   4.00000000e+00   4.00000000e+00\n",
      "   1.00000000e-01   1.00000000e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/optimize/minpack.py:715: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define the fitting function\n",
    "# We know that the velocities are \n",
    "# exhibiting a skew normal distribution\n",
    "def fit_vel_pdf((mlt,mlat, dst, inpVels), a_ascmlt, b_ascmlt, a_bscmlt, b_bscmlt, a_cscmlt, b_cscmlt,\\\n",
    "               a_asclat, b_asclat, a_bsclat, b_bsclat,\\\n",
    "               a_ashmlt, b_ashmlt, a_bshmlt, b_bshmlt,\\\n",
    "               a_ashlat, b_ashlat, a_bshlat, b_bshlat,\\\n",
    "               a_alcmlt, b_alcmlt, a_blcmlt, b_blcmlt,\\\n",
    "               a_alclat, b_alclat, a_blclat, b_blclat):\n",
    "    \n",
    "    # model scale parameters\n",
    "    # mlt\n",
    "    a_scale_mlt = a_ascmlt + b_ascmlt * dst\n",
    "    b_scale_mlt = a_bscmlt + b_bscmlt * dst\n",
    "    c_scale_mlt = a_cscmlt + b_cscmlt * dst\n",
    "    # mlat\n",
    "    a_scale_mlat = a_asclat + b_asclat * dst\n",
    "    b_scale_mlat = a_bsclat + b_bsclat * dst\n",
    "    # func\n",
    "    scale = ( a_scale_mlt + b_scale_mlt*(mlt) + c_scale_mlt*(mlt**2) ) * ( a_scale_mlat + b_scale_mlat*(mlat) )\n",
    "    \n",
    "    # model shape parameters\n",
    "    # mlt\n",
    "    a_shape_mlt = a_ashmlt + b_ashmlt * dst\n",
    "    b_shape_mlt = a_bshmlt + b_bshmlt * dst\n",
    "    # mlat\n",
    "    a_shape_mlat = a_ashlat + b_ashlat * dst\n",
    "    b_shape_mlat = a_bshlat + b_bshlat * dst\n",
    "    # func\n",
    "    shape = ( a_shape_mlt + b_shape_mlt*(mlt) ) * ( a_shape_mlat + b_shape_mlat*(mlat) )\n",
    "    \n",
    "    # model loc parameters\n",
    "    # mlt\n",
    "    a_loc_mlt = a_alcmlt + b_alcmlt * dst\n",
    "    b_loc_mlt = a_blcmlt + b_blcmlt * dst\n",
    "    # malt\n",
    "    a_loc_mlat = a_alclat + b_alclat * dst\n",
    "    b_loc_mlat = a_blclat + b_blclat * dst\n",
    "    # func\n",
    "    loc = ( a_loc_mlt + b_loc_mlt*(mlt) ) * ( a_loc_mlat*numpy.exp(b_loc_mlat*mlat) )\n",
    "    \n",
    "    # we need to adjust the skewnormal distribution\n",
    "    # to account fot loc and scale parameters\n",
    "    inpData = (inpVels - loc)/scale\n",
    "    skNrml = 2*stats.norm.pdf(inpData)*stats.norm.cdf(shape*inpData)\n",
    "    return skNrml.ravel()\n",
    "\n",
    "initGuess = ( -1e+4, -1e+4, 1e3, 1e3, -10, -10,\\\n",
    "             100, 100, 10, 10,\\\n",
    "             1, 1, 10, 10,\\\n",
    "            -1, -1, 100, 100,\\\n",
    "            -100, -100, 100, 100,\\\n",
    "            4, 4, 0.1, 0.1)\n",
    "popt2, pcov2 = curve_fit(fit_vel_pdf, (velGmagDF['MLAT'].T,velGmagDF['normMLT'].T,velGmagDF['dst_index'].T,\\\n",
    "                                       velGmagDF['vSaps'].T), velGmagDF['vSaps'], p0=initGuess)\n",
    "print popt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
