{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import numpy\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import ticker\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup some cutoff values we'll use in the analysis\n",
    "velCutoffUpper = 2000.\n",
    "velCutoffLower = 0.\n",
    "numPointsCutoffMLTMLAT = 250\n",
    "mlatCutOffUpper = 70.\n",
    "probOccCutoff = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:32: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normMLT</th>\n",
       "      <th>MLAT</th>\n",
       "      <th>vSaps</th>\n",
       "      <th>azim</th>\n",
       "      <th>dst_index</th>\n",
       "      <th>vel_bin</th>\n",
       "      <th>dst_bin</th>\n",
       "      <th>dst_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>164.32</td>\n",
       "      <td>-19.01</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>(100, 200]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>171.45</td>\n",
       "      <td>-16.11</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(100, 200]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>174.58</td>\n",
       "      <td>-14.80</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>(100, 200]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>176.98</td>\n",
       "      <td>-6.09</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>(100, 200]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>59.5</td>\n",
       "      <td>178.11</td>\n",
       "      <td>-6.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(100, 200]</td>\n",
       "      <td>(-10, 10]</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   normMLT  MLAT   vSaps   azim  dst_index     vel_bin    dst_bin  dst_mean\n",
       "0      1.0  58.5  164.32 -19.01       -7.0  (100, 200]  (-10, 10]        -3\n",
       "1      1.0  57.0  171.45 -16.11       -1.0  (100, 200]  (-10, 10]        -3\n",
       "2      1.0  59.0  174.58 -14.80       -7.0  (100, 200]  (-10, 10]        -3\n",
       "3      1.0  59.0  176.98  -6.09       -7.0  (100, 200]  (-10, 10]        -3\n",
       "4      2.0  59.5  178.11  -6.20        3.0  (100, 200]  (-10, 10]        -3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velGmagDF = pandas.read_csv(\"../data/processed-vels-geomag.txt\", sep=' ')\n",
    "velGmagDF = velGmagDF.drop('Unnamed: 0', axis=1)\n",
    "# Discard unwanted values\n",
    "# We'll only consider those velocities \n",
    "# which lie between 0 and 2500 m/s\n",
    "# and located below 70 MLAT\n",
    "velGmagDF = velGmagDF[ (velGmagDF[\"vSaps\"] > velCutoffLower) \\\n",
    "                        & (velGmagDF[\"vSaps\"] < velCutoffUpper)\\\n",
    "                       ].reset_index(drop=True)\n",
    "velGmagDF = velGmagDF[ velGmagDF[\"MLAT\"] < mlatCutOffUpper ].reset_index(drop=True)\n",
    "# Now filter out velocities which have very few rate of occ.\n",
    "# We calculat the prob and remove every measurement below 0.2 prob of occ.\n",
    "mlatMLTDstCountDF = velGmagDF.groupby( [\"MLAT\", \"normMLT\", \"dst_bin\"] )[\"vSaps\"].count().reset_index()\n",
    "mlatMLTDstCountDF.columns = [ \"MLAT\", \"normMLT\", \"dst_bin\", \"count\" ]\n",
    "dstMaxCntDF = mlatMLTDstCountDF.groupby( [\"dst_bin\"] )[\"count\"].max().reset_index()\n",
    "dstMaxCntDF.columns = [ \"dst_bin\", \"maxCntDst\" ]\n",
    "mlatMLTDstCountDF = pandas.merge( mlatMLTDstCountDF, dstMaxCntDF, on=[ \"dst_bin\" ] )\n",
    "mlatMLTDstCountDF[\"probOcc\"] = mlatMLTDstCountDF[\"count\"]/mlatMLTDstCountDF[\"maxCntDst\"]\n",
    "mlatMLTDstCountDF = mlatMLTDstCountDF[ mlatMLTDstCountDF[\"probOcc\"] > probOccCutoff ].reset_index(drop=True)\n",
    "# Filter out MLATs and MLTs (at the Dst bins)\n",
    "# where number of measurements is low. We do\n",
    "# this by merging the mlatMLTDstCountDF with velDF.\n",
    "velGmagDF = pandas.merge( velGmagDF,\\\n",
    "                         mlatMLTDstCountDF,\\\n",
    "                         on=[ \"MLAT\", \"normMLT\", \"dst_bin\" ] )\n",
    "velGmagDF = velGmagDF[ [ \"normMLT\", \"MLAT\", \"vSaps\",\\\n",
    "                        \"azim\", \"dst_bin\", \"dst_index\", \"count\", \"maxCntDst\" ] ]\n",
    "# Divide the velocities into bins\n",
    "velBins = [ v for v in range(0,int(velCutoffUpper)+100,100) ]\n",
    "velGmagDF = pandas.concat( [ velGmagDF, \\\n",
    "                    pandas.cut( velGmagDF[\"vSaps\"], \\\n",
    "                               bins=velBins ) ], axis=1 )\n",
    "velGmagDF.columns = [ \"normMLT\", \"MLAT\", \"vSaps\",\\\n",
    "                        \"azim\", \"dst_bin\", \"dst_index\", \"count\",\\\n",
    "                         \"maxCntDst\", \"vel_bin\" ]\n",
    "# velGmagDF.head()\n",
    "# Get a DF with mean Dst in each bin\n",
    "dstMeanDF = velGmagDF.groupby( [\"dst_bin\"] ).mean()[\"dst_index\"].astype(int).reset_index()\n",
    "dstMeanDF.columns = [ \"dst_bin\", \"dst_mean\" ]\n",
    "velGmagDF = pandas.merge( velGmagDF, dstMeanDF, on=[\"dst_bin\"] )\n",
    "velGmagDF = velGmagDF.sort( [\"dst_mean\", \"vSaps\"], ascending=[False,True] ).reset_index(drop=True)\n",
    "velCatOrderd = ['(0, 100]', '(100, 200]', '(200, 300]', '(300, 400]', '(400, 500]',\\\n",
    "          '(500, 600]', '(600, 700]', '(700, 800]',\\\n",
    "          '(800, 900]', '(900, 1000]', '(1000, 1100]', '(1100, 1200]',\\\n",
    "          '(1200, 1300]', '(1300, 1400]', '(1400, 1500]',\\\n",
    "          '(1500, 1600]', '(1600, 1700]', '(1700, 1800]',\\\n",
    "          '(1800, 1900]', '(1900, 2000]' ]\n",
    "\n",
    "velGmagDF['vel_bin'] = pandas.Categorical(\n",
    "    velGmagDF['vel_bin'], \n",
    "    categories=velCatOrderd, \n",
    "    ordered=True\n",
    ")\n",
    "# We need only a few cols\n",
    "velGmagDF = velGmagDF[ [ \"normMLT\", \"MLAT\", \"vSaps\", \"azim\", \"dst_index\",\\\n",
    "                        \"vel_bin\", \"dst_bin\", \"dst_mean\" ] ]\n",
    "velGmagDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:20: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "# calculate prob densities of vel bins at a given MLAT, MLT and Dst\n",
    "# We can them compare these with our estimates of skewnormal!!!\n",
    "probVelDstDF = velGmagDF.groupby( [ \"vel_bin\", \"dst_bin\", \"MLAT\", \"normMLT\" ] ).count()[\"vSaps\"].reset_index()\n",
    "probVelDstDF.columns = [ \"vel_bin\", \"dst_bin\", \"MLAT\", \"normMLT\", \"count\" ]\n",
    "# get the max count at dst, mlat and mlt\n",
    "maxCntVelDF = velGmagDF.groupby( [ \"dst_bin\", \"MLAT\", \"normMLT\" ] ).count()[\"vSaps\"].reset_index()\n",
    "maxCntVelDF.columns = [ \"dst_bin\", \"MLAT\", \"normMLT\", \"tot_count\" ]\n",
    "probVelDstDF = pandas.merge( probVelDstDF, maxCntVelDF, on=[ \"dst_bin\", \"MLAT\", \"normMLT\" ] )\n",
    "# Fill NaNs with zeros\n",
    "probVelDstDF[\"count\"].fillna(0.,inplace=True)\n",
    "# calculate probs\n",
    "probVelDstDF[\"prob\"] = probVelDstDF[\"count\"] / probVelDstDF[\"tot_count\"]\n",
    "probVelDstDF = probVelDstDF.round(2)\n",
    "velCatOrderd = ['(0, 100]', '(100, 200]', '(200, 300]', '(300, 400]', '(400, 500]',\\\n",
    "          '(500, 600]', '(600, 700]', '(700, 800]',\\\n",
    "          '(800, 900]', '(900, 1000]', '(1000, 1100]', '(1100, 1200]',\\\n",
    "          '(1200, 1300]', '(1300, 1400]', '(1400, 1500]',\\\n",
    "          '(1500, 1600]', '(1600, 1700]', '(1700, 1800]',\\\n",
    "          '(1800, 1900]', '(1900, 2000]' ]\n",
    "probVelDstDF['vel_bin'] = pandas.Categorical(\n",
    "    probVelDstDF['vel_bin'], \n",
    "    categories=velCatOrderd, \n",
    "    ordered=True\n",
    ")\n",
    "probVelDstDF = probVelDstDF.sort(\"vel_bin\")\n",
    "# Merge with velGmagDF to combine all cols we need to one DF\n",
    "velGmagDF = pandas.merge( probVelDstDF, velGmagDF,\\\n",
    "                            on=[ \"vel_bin\", \"dst_bin\", \"MLAT\", \"normMLT\" ] ).reset_index(drop=True)\n",
    "subSetProbDF = probVelDstDF[ (probVelDstDF[\"dst_bin\"] == \"(-150, -75]\") &\\\n",
    "                   (probVelDstDF[\"MLAT\"] == 59) &\\\n",
    "                   (probVelDstDF[\"normMLT\"] == -3)].reset_index(drop=True)\n",
    "\n",
    "subSetVelDF = velGmagDF[ (velGmagDF[\"dst_bin\"] == \"(-150, -75]\") &\\\n",
    "                   (velGmagDF[\"MLAT\"] == 59) &\\\n",
    "                   (velGmagDF[\"normMLT\"] == -3)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9670032243 448.243026922 286.028612421\n"
     ]
    }
   ],
   "source": [
    "velsArr = numpy.arange(0.,2100.,100.)\n",
    "shape, loc, scale = stats.skewnorm.fit(subSetVelDF[\"vSaps\"])\n",
    "pdf_fitted = stats.skewnorm.pdf(velsArr, shape, loc, scale)\n",
    "print shape, loc, scale\n",
    "\n",
    "f = plt.figure(figsize=(12, 8))\n",
    "ax = f.add_subplot(1,1,1)\n",
    "subSetProbDF.plot( x=\"vel_bin\", y=\"prob\", kind=\"bar\", ax=ax )\n",
    "ax.plot(velsArr, pdf_fitted, 'r-', lw=5, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:39: RuntimeWarning: divide by zero encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:40: RuntimeWarning: invalid value encountered in multiply\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.py:875: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.py:875: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/stats/_distn_infrastructure.py:1731: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  cond2 = (x >= self.b) & cond0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.00000000e+04  -1.00000000e+04   1.00000000e+03   1.00000000e+03\n",
      "  -1.00000000e+01  -1.00000000e+01   1.00000000e+02   1.00000000e+02\n",
      "   1.00000000e+01   1.00000000e+01   1.00000000e+00   1.00000000e+00\n",
      "   1.00000000e+01   1.00000000e+01  -1.00000000e+00  -1.00000000e+00\n",
      "   1.00000000e+02   1.00000000e+02  -1.00000000e+02  -1.00000000e+02\n",
      "   1.00000000e+02   1.00000000e+02   4.00000000e+00   4.00000000e+00\n",
      "   1.00000000e-01   1.00000000e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/optimize/minpack.py:715: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define the fitting function\n",
    "# We know that the velocities are \n",
    "# exhibiting a skew normal distribution\n",
    "def fit_vel_pdf((mlt,mlat, dst, inpVels), a_ascmlt, b_ascmlt, a_bscmlt, b_bscmlt, a_cscmlt, b_cscmlt,\\\n",
    "               a_asclat, b_asclat, a_bsclat, b_bsclat,\\\n",
    "               a_ashmlt, b_ashmlt, a_bshmlt, b_bshmlt,\\\n",
    "               a_ashlat, b_ashlat, a_bshlat, b_bshlat,\\\n",
    "               a_alcmlt, b_alcmlt, a_blcmlt, b_blcmlt,\\\n",
    "               a_alclat, b_alclat, a_blclat, b_blclat):\n",
    "    \n",
    "    # model scale parameters\n",
    "    # mlt\n",
    "    a_scale_mlt = a_ascmlt + b_ascmlt * dst\n",
    "    b_scale_mlt = a_bscmlt + b_bscmlt * dst\n",
    "    c_scale_mlt = a_cscmlt + b_cscmlt * dst\n",
    "    # mlat\n",
    "    a_scale_mlat = a_asclat + b_asclat * dst\n",
    "    b_scale_mlat = a_bsclat + b_bsclat * dst\n",
    "    # func\n",
    "    scale = ( a_scale_mlt + b_scale_mlt*(mlt) + c_scale_mlt*(mlt**2) ) * ( a_scale_mlat + b_scale_mlat*(mlat) )\n",
    "    \n",
    "    # model shape parameters\n",
    "    # mlt\n",
    "    a_shape_mlt = a_ashmlt + b_ashmlt * dst\n",
    "    b_shape_mlt = a_bshmlt + b_bshmlt * dst\n",
    "    # mlat\n",
    "    a_shape_mlat = a_ashlat + b_ashlat * dst\n",
    "    b_shape_mlat = a_bshlat + b_bshlat * dst\n",
    "    # func\n",
    "    shape = ( a_shape_mlt + b_shape_mlt*(mlt) ) * ( a_shape_mlat + b_shape_mlat*(mlat) )\n",
    "    \n",
    "    # model loc parameters\n",
    "    # mlt\n",
    "    a_loc_mlt = a_alcmlt + b_alcmlt * dst\n",
    "    b_loc_mlt = a_blcmlt + b_blcmlt * dst\n",
    "    # malt\n",
    "    a_loc_mlat = a_alclat + b_alclat * dst\n",
    "    b_loc_mlat = a_blclat + b_blclat * dst\n",
    "    # func\n",
    "    loc = ( a_loc_mlt + b_loc_mlt*(mlt) ) * ( a_loc_mlat*numpy.exp(b_loc_mlat*mlat) )\n",
    "    \n",
    "    # we need to adjust the skewnormal distribution\n",
    "    # to account fot loc and scale parameters\n",
    "    inpData = (inpVels - loc)/scale\n",
    "    skNrml = 2*stats.norm.pdf(inpData)*stats.norm.cdf(shape*inpData)\n",
    "     \n",
    "    return skNrml.ravel()\n",
    "\n",
    "initGuess = ( -1e+4, -1e+4, 1e3, 1e3, -10, -10,\\\n",
    "             100, 100, 10, 10,\\\n",
    "             1, 1, 10, 10,\\\n",
    "            -1, -1, 100, 100,\\\n",
    "            -100, -100, 100, 100,\\\n",
    "            4, 4, 0.1, 0.1)\n",
    "popt2, pcov2 = curve_fit(fit_vel_pdf, (velGmagDF['MLAT'].T,velGmagDF['normMLT'].T,velGmagDF['dst_index'].T,\\\n",
    "                                       velGmagDF['vSaps'].T), velGmagDF['vSaps'], p0=initGuess)\n",
    "print popt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15865525  0.84134475  0.97724987  0.97724987  0.97724987  0.9986501\n",
      "  0.99996833]\n"
     ]
    }
   ],
   "source": [
    "aa = [ -1,1,2,2,2,3,4 ]\n",
    "print stats.norm.cdf(aa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
